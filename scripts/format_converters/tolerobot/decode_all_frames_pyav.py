import logging
from pathlib import Path
from typing import Optional, Tuple

import av
import numpy as np
import torch


def decode_all_video_frames_pyav(
    video_path: Path | str,
    device: str = "cpu",
    log_progress: bool = False,
    return_tensors: bool = True,
) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor]]:
    """
    ä½¿ç”¨ PyAV è¯»å–è§†é¢‘ä¸­çš„æ‰€æœ‰å¸§ï¼Œå¹¶è¿”å›å¸§å¼ é‡å’Œæ—¶é—´æˆ³ã€‚

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        device: è¾“å‡ºå¼ é‡æ‰€åœ¨è®¾å¤‡ï¼ˆä»…åœ¨ return_tensors=True æ—¶æœ‰æ•ˆï¼‰
        log_progress: æ˜¯å¦æ‰“å°è¿›åº¦
        return_tensors: æ˜¯å¦è¿”å› torch.Tensorï¼›è‹¥ Falseï¼Œåˆ™è¿”å› ndarray åˆ—è¡¨

    Returns:
        frames: å½¢çŠ¶ä¸º (N, C, H, W) çš„å¼ é‡ï¼Œå€¼åœ¨ [0,1] èŒƒå›´å†…ï¼Œdtype=torch.float32
                æˆ– Noneï¼ˆå¦‚æœè§£ç å¤±è´¥ï¼‰
        timestamps: å½¢çŠ¶ä¸º (N,) çš„å¼ é‡ï¼ŒåŒ…å«æ¯å¸§çš„ PTSï¼ˆç§’ï¼‰ï¼Œå•ä½ï¼šç§’

    æ³¨æ„ï¼š
        - PyAV å¯¹æŸäº›ç¼–ç å¼‚å¸¸æ›´æ•æ„Ÿï¼ˆå¦‚ B-frame é”™è¯¯ã€NAL æŸåï¼‰ï¼Œé€‚åˆåšâ€œè´¨æ£€â€
        - è‹¥æŸå¸§è§£ç å¤±è´¥ï¼Œä¼šè·³è¿‡å¹¶è®°å½•è­¦å‘Š
    """
    video_path = str(video_path)
    print(video_path)
    try:
        container = av.open(video_path)
    except Exception as e:
        logging.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}, é”™è¯¯: {e}")
        return None, None

    # è·å–è§†é¢‘æµï¼ˆç¬¬ä¸€ä¸ªè§†é¢‘æµï¼‰
    video_stream = None
    for stream in container.streams:
        if stream.type == "video":
            video_stream = stream
            break

    if not video_stream:
        logging.error(f"âŒ è§†é¢‘ä¸­æœªæ‰¾åˆ°è§†é¢‘æµ: {video_path}")
        container.close()
        return None, None

    # è®¾ç½®è§£ç å™¨å‚æ•°ï¼ˆæé«˜å®¹é”™æ€§ï¼‰
    video_stream.thread_type = "AUTO"
    # å¯é€‰ï¼šè®¾ç½®æœ€å¤§åˆ†ææ—¶é•¿ï¼ˆé¿å…å¡ä½ï¼‰
    # container.streams.video[0].codec_context.skip_frame = 'NONKEY'  # è·³è¿‡éå…³é”®å¸§ï¼ˆå¯é€‰ï¼‰

    frames = []
    timestamps = []

    frame_idx = 0
    try:
        for packet in container.demux(video_stream):
            try:
                for frame in packet.decode():
                    # è·å–å¸§æ•°æ® (H, W, C)
                    img = frame.to_ndarray(format="rgb24")

                    # è·å–æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                    pts = frame.pts
                    time_base = video_stream.time_base
                    timestamp_sec = (
                        float(pts * time_base)
                        if pts is not None
                        else float(frame_idx / video_stream.average_rate)
                    )

                    frames.append(img)
                    timestamps.append(timestamp_sec)

                    if log_progress and frame_idx % 100 == 0:
                        logging.info(f"âœ… è§£ç å¸§ {frame_idx}, PTS={timestamp_sec:.4f}s")

            except Exception as e:
                logging.warning(f"âš ï¸ è§£ç  packet æ—¶å‡ºé”™ï¼ˆè·³è¿‡ï¼‰: å¸§ {frame_idx}, é”™è¯¯: {e}")
            finally:
                frame_idx += 1

    except Exception as e:
        logging.error(f"ğŸ”¥ è§£ç è¿‡ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
    finally:
        container.close()

    if len(frames) == 0:
        logging.error(f"âŒ æœªè§£ç å‡ºä»»ä½•å¸§: {video_path}")
        return None, None

    if not return_tensors:
        return frames, np.array(timestamps, dtype=np.float32)

    # è½¬æ¢ä¸º torch.Tensor
    try:
        tensor_frames = torch.stack(
            [torch.from_numpy(img).permute(2, 0, 1) for img in frames]
        )  # (N, C, H, W)
        tensor_frames = tensor_frames.float() / 255.0
        tensor_frames = tensor_frames.to(device)
        ts_tensor = torch.tensor(timestamps, dtype=torch.float32).to(device)
    except Exception as e:
        logging.error(f"âŒ è½¬æ¢ä¸º torch.Tensor å¤±è´¥: {e}")
        return None, None

    if log_progress:
        logging.info(f"âœ… æˆåŠŸè§£ç  {len(frames)} å¸§ from {video_path}")

    return tensor_frames, ts_tensor


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Decode all video frames using torchcodec.")
    parser.add_argument("video_path", type=str, help="Path to the video file.")
    parser.add_argument(
        "--device", type=str, default="cpu", help="Device to use for decoding (cpu or cuda)."
    )
    parser.add_argument("--log_progress", action="store_true", help="Log progress during decoding.")
    args = parser.parse_args()

    frames, timestamps = decode_all_video_frames_pyav(
        video_path=args.video_path,
        device=args.device,
        log_progress=args.log_progress,
    )
