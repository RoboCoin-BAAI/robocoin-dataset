"""
æ—¶é—´åŒæ­¥åˆ†æå™¨
ç”¨äºåˆ†æRosBagæ•°æ®çš„æ—¶é—´åˆ†å¸ƒå’ŒåŒæ­¥è´¨é‡
"""
from dataclasses import dataclass

import numpy as np


@dataclass
class TopicTimeStats:
    """å•ä¸ªtopicçš„æ—¶é—´ç»Ÿè®¡ä¿¡æ¯"""
    topic_name: str
    message_count: int
    time_range_sec: float
    avg_frequency_hz: float
    std_frequency_hz: float
    time_gaps_ms: list[float]
    max_gap_ms: float
    min_gap_ms: float


@dataclass
class SyncQualityReport:
    """æ—¶é—´åŒæ­¥è´¨é‡æŠ¥å‘Š"""
    overall_quality_score: float  # 0-1ä¹‹é—´ï¼Œ1ä¸ºå®Œç¾åŒæ­¥
    topic_stats: dict[str, TopicTimeStats]
    alignment_feasibility: str  # "excellent", "good", "poor", "impossible"
    recommended_strategy: str
    base_topic_candidates: list[str]
    potential_issues: list[str]
    data_loss_estimate: float  # é¢„ä¼°çš„æ•°æ®æŸå¤±ç™¾åˆ†æ¯”


class TimeSyncAnalyzer:
    """æ—¶é—´åŒæ­¥åˆ†æå™¨"""
    
    def __init__(self, logger=None) -> None:  # noqa: ANN001
        self.logger = logger
        
    def analyze_topic_messages(self, topic_messages: dict[str, list[dict]]) -> SyncQualityReport:
        """
        åˆ†ætopicæ¶ˆæ¯çš„æ—¶é—´åŒæ­¥è´¨é‡
        
        Args:
            topic_messages: {topic_name: [{'timestamp': xxx, 'data': xxx}, ...]}
            
        Returns:
            SyncQualityReport: åŒæ­¥è´¨é‡æŠ¥å‘Š
        """
        topic_stats = {}
        
        # åˆ†ææ¯ä¸ªtopicçš„æ—¶é—´ç»Ÿè®¡
        for topic_name, messages in topic_messages.items():
            if not messages:
                continue
                
            topic_stats[topic_name] = self._analyze_topic_timing(topic_name, messages)
        
        # è®¡ç®—æ•´ä½“åŒæ­¥è´¨é‡
        quality_score = self._calculate_sync_quality(topic_stats)
        
        # åˆ†æå¯¹é½å¯è¡Œæ€§
        feasibility = self._assess_alignment_feasibility(topic_stats)
        
        # æ¨èç­–ç•¥
        strategy = self._recommend_strategy(topic_stats, quality_score)
        
        # é€‰æ‹©åŸºå‡†topicå€™é€‰
        base_candidates = self._select_base_topic_candidates(topic_stats)
        
        # è¯†åˆ«æ½œåœ¨é—®é¢˜
        issues = self._identify_issues(topic_stats)
        
        # ä¼°ç®—æ•°æ®æŸå¤±
        data_loss = self._estimate_data_loss(topic_stats)
        
        return SyncQualityReport(
            overall_quality_score=quality_score,
            topic_stats=topic_stats,
            alignment_feasibility=feasibility,
            recommended_strategy=strategy,
            base_topic_candidates=base_candidates,
            potential_issues=issues,
            data_loss_estimate=data_loss
        )
    
    def _analyze_topic_timing(self, topic_name: str, messages: list[dict]) -> TopicTimeStats:
        """åˆ†æå•ä¸ªtopicçš„æ—¶é—´ç»Ÿè®¡"""
        timestamps = [msg['timestamp'] for msg in messages]
        
        if len(timestamps) < 2:
            return TopicTimeStats(
                topic_name=topic_name,
                message_count=len(timestamps),
                time_range_sec=0.0,
                avg_frequency_hz=0.0,
                std_frequency_hz=0.0,
                time_gaps_ms=[],
                max_gap_ms=0.0,
                min_gap_ms=0.0
            )
        
        # è½¬æ¢ä¸ºç§’
        timestamps_sec = [ts / 1e9 for ts in timestamps]
        time_range = max(timestamps_sec) - min(timestamps_sec)
        
        # è®¡ç®—æ—¶é—´é—´éš”
        time_gaps = [timestamps_sec[i+1] - timestamps_sec[i] for i in range(len(timestamps_sec)-1)]
        time_gaps_ms = [gap * 1000 for gap in time_gaps]
        
        # é¢‘ç‡ç»Ÿè®¡
        if time_range > 0:
            avg_frequency = len(timestamps) / time_range
        else:
            avg_frequency = 0.0
        
        # ç¬æ—¶é¢‘ç‡æ ‡å‡†å·®
        if len(time_gaps) > 0:
            instant_freqs = [1.0 / gap for gap in time_gaps if gap > 0]
            std_frequency = np.std(instant_freqs) if instant_freqs else 0.0
        else:
            std_frequency = 0.0
        
        return TopicTimeStats(
            topic_name=topic_name,
            message_count=len(timestamps),
            time_range_sec=time_range,
            avg_frequency_hz=avg_frequency,
            std_frequency_hz=std_frequency,
            time_gaps_ms=time_gaps_ms,
            max_gap_ms=max(time_gaps_ms) if time_gaps_ms else 0.0,
            min_gap_ms=min(time_gaps_ms) if time_gaps_ms else 0.0
        )
    
    def _calculate_sync_quality(self, topic_stats: dict[str, TopicTimeStats]) -> float:
        """è®¡ç®—æ•´ä½“åŒæ­¥è´¨é‡åˆ†æ•° (0-1)"""
        if not topic_stats:
            return 0.0
        
        scores = []
        
        for stats in topic_stats.values():
            # é¢‘ç‡ç¨³å®šæ€§å¾—åˆ†
            if stats.avg_frequency_hz > 0:
                freq_stability = max(0, 1 - (stats.std_frequency_hz / stats.avg_frequency_hz))
            else:
                freq_stability = 0.0
            
            # æ—¶é—´é—´éš”å‡åŒ€æ€§å¾—åˆ†
            if stats.time_gaps_ms:
                gap_uniformity = max(0, 1 - (np.std(stats.time_gaps_ms) / np.mean(stats.time_gaps_ms)))
            else:
                gap_uniformity = 0.0
            
            # ç»¼åˆå¾—åˆ†
            topic_score = (freq_stability + gap_uniformity) / 2
            scores.append(topic_score)
        
        return np.mean(scores) if scores else 0.0
    
    def _assess_alignment_feasibility(self, topic_stats: dict[str, TopicTimeStats]) -> str:
        """è¯„ä¼°å¯¹é½å¯è¡Œæ€§"""
        if not topic_stats:
            return "impossible"
        
        frequencies = [stats.avg_frequency_hz for stats in topic_stats.values() if stats.avg_frequency_hz > 0]
        
        if not frequencies:
            return "impossible"
        
        freq_ratio = max(frequencies) / min(frequencies)
        
        if freq_ratio <= 2:
            return "excellent"
        if freq_ratio <= 5:
            return "good" 
        if freq_ratio <= 20:
            return "poor"
        return "impossible"
    
    def _recommend_strategy(self, topic_stats: dict[str, TopicTimeStats], quality_score: float) -> str:
        """æ¨èå¯¹é½ç­–ç•¥"""
        if quality_score > 0.8:
            return "interpolation"
        if quality_score > 0.5:
            return "nearest_neighbor"
        return "emergency"
    
    def _select_base_topic_candidates(self, topic_stats: dict[str, TopicTimeStats]) -> list[str]:
        """é€‰æ‹©åŸºå‡†topicå€™é€‰"""
        
        # ä¼˜å…ˆçº§å…³é”®è¯
        priority_keywords = ['rgb', 'color', 'image', 'camera', 'compressed', 'depth']
        
        # æŒ‰ä¼˜å…ˆçº§å’Œé¢‘ç‡ç¨³å®šæ€§æ’åº
        topic_scores = []
        for topic_name, stats in topic_stats.items():
            # å…³é”®è¯åŒ¹é…å¾—åˆ†
            keyword_score = 0
            for i, keyword in enumerate(priority_keywords):
                if keyword in topic_name.lower():
                    keyword_score = len(priority_keywords) - i
                    break
            
            # é¢‘ç‡ç¨³å®šæ€§å¾—åˆ†
            if stats.avg_frequency_hz > 0 and stats.std_frequency_hz >= 0:
                stability_score = max(0, 1 - (stats.std_frequency_hz / stats.avg_frequency_hz))
            else:
                stability_score = 0
            
            # æ¶ˆæ¯æ•°é‡å¾—åˆ†ï¼ˆå½’ä¸€åŒ–ï¼‰
            msg_count_score = min(1.0, stats.message_count / 1000)
            
            total_score = keyword_score * 0.5 + stability_score * 0.3 + msg_count_score * 0.2
            topic_scores.append((topic_name, total_score))
        
        # æ’åºå¹¶è¿”å›å‰ä¸‰å
        topic_scores.sort(key=lambda x: x[1], reverse=True)
        return [topic for topic, _ in topic_scores[:3]]
    
    def _identify_issues(self, topic_stats: dict[str, TopicTimeStats]) -> list[str]:
        """è¯†åˆ«æ½œåœ¨é—®é¢˜"""
        issues = []
        
        if not topic_stats:
            issues.append("No topic data available")
            return issues
        
        # æ£€æŸ¥é¢‘ç‡å·®å¼‚
        frequencies = [stats.avg_frequency_hz for stats in topic_stats.values() if stats.avg_frequency_hz > 0]
        if frequencies:
            freq_ratio = max(frequencies) / min(frequencies)
            if freq_ratio > 10:
                issues.append(f"Extreme frequency differences (ratio: {freq_ratio:.1f}x)")
            elif freq_ratio > 5:
                issues.append(f"High frequency differences (ratio: {freq_ratio:.1f}x)")
        
        # æ£€æŸ¥é¢‘ç‡ä¸ç¨³å®š
        unstable_topics = [
            stats.topic_name for stats in topic_stats.values()
            if stats.avg_frequency_hz > 0 and (stats.std_frequency_hz / stats.avg_frequency_hz) > 0.5
        ]
        if unstable_topics:
            issues.append(f"Unstable frequencies in topics: {', '.join(unstable_topics[:3])}")
        
        # æ£€æŸ¥æ•°æ®ç¨€å°‘
        sparse_topics = [
            stats.topic_name for stats in topic_stats.values()
            if stats.message_count < 10
        ]
        if sparse_topics:
            issues.append(f"Sparse data in topics: {', '.join(sparse_topics[:3])}")
        
        # æ£€æŸ¥æ—¶é—´é—´éš”å¼‚å¸¸
        gap_issues = []
        for stats in topic_stats.values():
            if stats.time_gaps_ms and stats.max_gap_ms > 1000:  # 1ç§’ä»¥ä¸Šçš„é—´éš”
                gap_issues.append(stats.topic_name)  # noqa: PERF401
        if gap_issues:
            issues.append(f"Large time gaps in topics: {', '.join(gap_issues[:3])}")
        
        return issues
    
    def _estimate_data_loss(self, topic_stats: dict[str, TopicTimeStats]) -> float:
        """ä¼°ç®—ä½¿ç”¨åº”æ€¥ç­–ç•¥çš„æ•°æ®æŸå¤±ç™¾åˆ†æ¯”"""
        if not topic_stats:
            return 0.0
        
        message_counts = [stats.message_count for stats in topic_stats.values()]
        min_count = min(message_counts)
        total_messages = sum(message_counts)
        
        if total_messages == 0:
            return 0.0
        
        preserved_messages = min_count * len(message_counts)
        return (total_messages - preserved_messages) / total_messages
        
    
    def print_analysis_report(self, report: SyncQualityReport) -> None:
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("=" * 80)
        print("ğŸ” ROS Bag æ—¶é—´åŒæ­¥è´¨é‡åˆ†ææŠ¥å‘Š")
        print("=" * 80)
        
        print("\nğŸ“Š æ•´ä½“è¯„ä¼°:")
        print(f"   åŒæ­¥è´¨é‡å¾—åˆ†: {report.overall_quality_score:.3f} / 1.000")
        print(f"   å¯¹é½å¯è¡Œæ€§: {report.alignment_feasibility}")
        print(f"   æ¨èç­–ç•¥: {report.recommended_strategy}")
        print(f"   é¢„ä¼°æ•°æ®æŸå¤±: {report.data_loss_estimate:.1%}")
        
        print("\nğŸ¯ æ¨èåŸºå‡†Topics:")
        for i, topic in enumerate(report.base_topic_candidates, 1):
            print(f"   {i}. {topic}")
        
        print("\nğŸ“ˆ Topic ç»Ÿè®¡ä¿¡æ¯:")
        for topic, stats in report.topic_stats.items():
            print(f"\n   ğŸ“Œ {topic}")
            print(f"      æ¶ˆæ¯æ•°é‡: {stats.message_count}")
            print(f"      å¹³å‡é¢‘ç‡: {stats.avg_frequency_hz:.1f} Hz")
            print(f"      é¢‘ç‡ç¨³å®šæ€§: Â±{stats.std_frequency_hz:.1f} Hz")
            print(f"      æ—¶é—´è·¨åº¦: {stats.time_range_sec:.1f} ç§’")
            if stats.time_gaps_ms:
                print(f"      æ—¶é—´é—´éš”: {stats.min_gap_ms:.1f} - {stats.max_gap_ms:.1f} ms")
        
        if report.potential_issues:
            print("\nâš ï¸  æ½œåœ¨é—®é¢˜:")
            for issue in report.potential_issues:
                print(f"   â€¢ {issue}")
        
        print("\nğŸ’¡ å»ºè®®:")
        if report.alignment_feasibility == "excellent":
            print("   â€¢ æ—¶é—´åŒæ­¥è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ä½¿ç”¨æ’å€¼å¯¹é½è·å¾—æœ€ä½³æ•ˆæœ")
        elif report.alignment_feasibility == "good":
            print("   â€¢ æ—¶é—´åŒæ­¥è´¨é‡è‰¯å¥½ï¼Œå»ºè®®ä½¿ç”¨æ’å€¼æˆ–æœ€è¿‘é‚»å¯¹é½")
        elif report.alignment_feasibility == "poor":
            print("   â€¢ æ—¶é—´åŒæ­¥è´¨é‡è¾ƒå·®ï¼Œå»ºè®®ä½¿ç”¨æœ€è¿‘é‚»æˆ–åº”æ€¥å¯¹é½")
        else:
            print("   â€¢ æ—¶é—´åŒæ­¥å›°éš¾ï¼Œå»ºè®®ä½¿ç”¨åº”æ€¥å¯¹é½æˆ–è€ƒè™‘æ•°æ®é¢„å¤„ç†")
        
        print("=" * 80)
